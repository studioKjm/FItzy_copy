"""
ì¶”ì²œ ì½”ë”” AI ì´ë¯¸ì§€ ìƒì„± ìœ í‹¸ë¦¬í‹°
Stable Diffusion, DALL-E ë“± ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ì§€ì›
"""

import os
from PIL import Image
import io
import requests
from typing import Optional, Dict, List


class OutfitImageGenerator:
    """ì¶”ì²œ ì½”ë”” AI ì´ë¯¸ì§€ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, method: str = "huggingface_api", use_prototype: bool = True):
        """
        Args:
            method: ì´ë¯¸ì§€ ìƒì„± ë°©ë²•
                - "huggingface_api": Hugging Face Inference API (ì¶”ì²œ, ë¬´ë£Œ í‹°ì–´)
                - "dall_e": OpenAI DALL-E API (ìœ ë£Œ, ê³ í’ˆì§ˆ)
                - "stable_diffusion": ë¡œì»¬ Stable Diffusion (ë¬´ë£Œ, GPU í•„ìš”)
                - "stability_ai": Stability AI API (ìœ ë£Œ)
        """
        self.method = method
        self.api_key = None
        self.use_prototype = use_prototype  # í”„ë¡œí† íƒ€ì… ì‚¬ìš© ì—¬ë¶€
        
        # API í‚¤ ì„¤ì •
        if method == "dall_e":
            self.api_key = os.getenv("OPENAI_API_KEY")
        elif method == "stability_ai":
            self.api_key = os.getenv("STABILITY_AI_API_KEY")
        elif method == "huggingface_api":
            # Hugging Face API í‚¤ëŠ” ì„ íƒì  (ë¬´ë£Œ í‹°ì–´ëŠ” í‚¤ ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥)
            # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆìœ¼ë©´ Noneìœ¼ë¡œ ì²˜ë¦¬
            api_key = os.getenv("HUGGINGFACE_API_KEY", "").strip()
            self.api_key = api_key if api_key else None
        
        # í”„ë¡œí† íƒ€ì… ë§¤ë‹ˆì € ì´ˆê¸°í™” (Stable Diffusion ë¡œì»¬ë§Œ ì§€ì›)
        if use_prototype and method == "stable_diffusion":
            try:
                from src.utils.face_prototype_manager import FacePrototypeManager
                self.prototype_manager = FacePrototypeManager()
            except:
                self.use_prototype = False
                self.prototype_manager = None
        else:
            self.prototype_manager = None
    
    def generate_outfit_image(self, outfit_description: Dict, style_info: Dict = None) -> Optional[Image.Image]:
        """
        ì½”ë”” ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ AI ì´ë¯¸ì§€ ìƒì„±
        í”„ë¡œí† íƒ€ì…ì´ ìˆìœ¼ë©´ ì˜ìƒë§Œ ë³€ê²½í•˜ì—¬ ë¹ ë¥´ê²Œ ìƒì„±
        
        Args:
            outfit_description: ì½”ë”” ì„¤ëª… ë”•ì…”ë„ˆë¦¬
                - items: ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["ë¹¨ê°„ ìƒì˜", "íŒŒë€ ë°”ì§€"])
                - style: ìŠ¤íƒ€ì¼ (ì˜ˆ: "ìºì£¼ì–¼")
                - colors: ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸
                - gender: ì„±ë³„ ("ë‚¨ì„±", "ì—¬ì„±", "ê³µìš©")
            style_info: ì¶”ê°€ ìŠ¤íƒ€ì¼ ì •ë³´
        
        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ (PIL Image) ë˜ëŠ” None
        """
        # í”„ë¡œí† íƒ€ì… ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        gender = outfit_description.get("gender", "ê³µìš©")
        use_prototype_mode = (
            self.use_prototype and 
            self.method == "stable_diffusion" and 
            self.prototype_manager and
            gender != "ê³µìš©"  # ê³µìš©ì€ í”„ë¡œí† íƒ€ì… ë¯¸ì‚¬ìš©
        )
        
        if use_prototype_mode:
            # í”„ë¡œí† íƒ€ì… ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± (ì˜ìƒë§Œ ë³€ê²½)
            return self._generate_with_prototype(outfit_description, style_info)
        else:
            # ê¸°ì¡´ ë°©ì‹ (ì „ì²´ ì´ë¯¸ì§€ ìƒì„±)
            prompt = self._build_prompt(outfit_description, style_info)
            try:
                if self.method == "huggingface_api":
                    return self._generate_with_huggingface_api(prompt)
                elif self.method == "dall_e":
                    return self._generate_with_dalle(prompt)
                elif self.method == "stable_diffusion":
                    return self._generate_with_stable_diffusion_local(prompt)
                elif self.method == "stability_ai":
                    return self._generate_with_stability_ai(prompt)
                else:
                    print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë°©ë²•: {self.method}")
                    return None
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
                return None
    
    def _build_prompt(self, outfit_description: Dict, style_info: Dict = None) -> str:
        """íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (CLIP í† í¬ë‚˜ì´ì € 77 í† í° ì œí•œ ê³ ë ¤)"""
        items = outfit_description.get("items", [])
        style = outfit_description.get("style", "ìºì£¼ì–¼")
        colors = outfit_description.get("colors", [])
        gender = outfit_description.get("gender", "ê³µìš©")  # ì„±ë³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        # ì„±ë³„ í‚¤ì›Œë“œ ê²°ì •
        if gender == "ë‚¨ì„±":
            gender_keyword = "male model, man"
        elif gender == "ì—¬ì„±":
            gender_keyword = "female model, woman"
        else:
            gender_keyword = "model"  # ê³µìš© ë˜ëŠ” ë¯¸ì§€ì •
        
        # ì•„ì´í…œê³¼ ìƒ‰ìƒì„ ì •í™•í•˜ê²Œ ë§¤í•‘
        # itemsê°€ "ê²€ì€ìƒ‰ ê¸´íŒ” ìƒì˜" í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        # itemsê°€ ì¼ë°˜ ì´ë¦„ì´ë©´ colorsì™€ ê²°í•©
        
        # í•œêµ­ì–´ ìƒ‰ìƒ â†’ ì˜ì–´ ë³€í™˜
        color_map = {
            "ê²€ì€ìƒ‰": "black", "í°ìƒ‰": "white", "ë¹¨ê°„ìƒ‰": "red", "íŒŒë€ìƒ‰": "blue",
            "ë…¸ë€ìƒ‰": "yellow", "ì´ˆë¡ìƒ‰": "green", "ë³´ë¼ìƒ‰": "purple", "ë¶„í™ìƒ‰": "pink",
            "íšŒìƒ‰": "gray", "ê°ˆìƒ‰": "brown", "ë² ì´ì§€": "beige", "íŒŒìŠ¤í…”": "pastel",
            "black": "black", "white": "white", "red": "red", "blue": "blue"
        }
        
        # ì•„ì´í…œ ì²˜ë¦¬: ì´ë¯¸ ìƒ‰ìƒì´ í¬í•¨ëœ ê²½ìš°ì™€ ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°
        # ìµœëŒ€ 3ê°œê¹Œì§€ í¬í•¨ (ì¬í‚·, ê°€ë””ê±´ ë“± ë ˆì´ì–´ë“œ ì•„ì´í…œ í‘œí˜„)
        processed_items = []
        for item in items[:3]:  # ìµœëŒ€ 3ê°œë¡œ ì¦ê°€
            item_lower = item.lower()
            
            # ì œí’ˆëª…/ë¸Œëœë“œëª… ì œê±° (ì˜ìƒ ì„¤ëª…ë§Œ ì‚¬ìš©)
            # "ìœ ë‹ˆí´ë¡œ", "ë¦¬ë°”ì´ìŠ¤", "ì»¨ë²„ìŠ¤" ë“± ë¸Œëœë“œëª… ì œê±°
            brand_keywords = ["ìœ ë‹ˆí´ë¡œ", "ë¦¬ë°”ì´ìŠ¤", "ì»¨ë²„ìŠ¤", "ë‚˜ì´í‚¤", "ì•„ë””ë‹¤ìŠ¤", "uniqlo", "levis", "converse", "nike", "adidas", "u ", "U "]
            for brand in brand_keywords:
                item_lower = item_lower.replace(brand, "")
                item = item.replace(brand, "").replace(brand.capitalize(), "").replace(brand.upper(), "")
            
            # ë¶ˆí•„ìš”í•œ ì œí’ˆëª… í‚¤ì›Œë“œ ì œê±°
            product_keywords = ["í¬ë£¨ë„¥", "crew neck", "u í¬ë£¨ë„¥", "511", "ì²™í…Œì¼ëŸ¬", "chuck taylor", "ìŠ¬ë¦¼ì§„", "slim", "ìŠ¤íƒ ìŠ¤ë¯¸ìŠ¤", "stansmith", "ì•„í¬í…Œë¦­ìŠ¤", "arcteryx", "í…Œí¬í”Œë¦¬ìŠ¤", "tech fleece", "ì‚´ë¡œëª¬", "salomon", "xt-6"]
            for keyword in product_keywords:
                if keyword in item_lower:
                    # ì œí’ˆëª…ì€ ì œê±°í•˜ê³  ì˜ìƒ íƒ€ì…ë§Œ ë‚¨ê¹€
                    item = item.replace(keyword, "").strip()
            
            # ë°”ì§€ íƒ€ì… ëª…í™•í™” (ë°˜ë°”ì§€ ë°©ì§€)
            if "ë°”ì§€" in item_lower or "pants" in item_lower:
                if "ë°˜ë°”ì§€" not in item_lower and "shorts" not in item_lower:
                    # ê¸´ë°”ì§€ë¡œ ëª…ì‹œ
                    item = item.replace("ë°”ì§€", "long pants").replace("pants", "long pants")
            
            # ì•¡ì„¸ì„œë¦¬ íƒ€ì… ëª…í™•í™”
            if "ì•¡ì„¸ì„œë¦¬" in item_lower or "accessory" in item_lower:
                # ì¼ë°˜ì ì¸ ì•¡ì„¸ì„œë¦¬ëŠ” ëª¨ì/ìº¡ìœ¼ë¡œ êµ¬ì²´í™” (ê¸°ë³¸ê°’)
                item = item.replace("ì•¡ì„¸ì„œë¦¬", "cap").replace("accessory", "cap")
            
            # ì •ë¦¬: ê³µë°± ì œê±° ë° ì˜ìƒ íƒ€ì… ëª…í™•í™”
            item = " ".join(item.split())  # ì¤‘ë³µ ê³µë°± ì œê±°
            
            # "ì•ì¹˜ë§ˆ", "ì—ì´í”„ëŸ°" ê°™ì€ í‚¤ì›Œë“œê°€ í˜¼ë™ë˜ëŠ” ê²ƒì„ ë°©ì§€
            if "ì•ì¹˜ë§ˆ" in item_lower or "ì—ì´í”„ëŸ°" in item_lower or "apron" in item_lower:
                # ì•ì¹˜ë§ˆ ê´€ë ¨ í‚¤ì›Œë“œ ì œê±°
                item = item.replace("ì•ì¹˜ë§ˆ", "").replace("ì—ì´í”„ëŸ°", "").replace("apron", "").strip()
            
            # ìƒ‰ìƒì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            has_color = any(color in item_lower for color in ["ê²€ì€ìƒ‰", "í°ìƒ‰", "ë¹¨ê°„ìƒ‰", "íŒŒë€ìƒ‰", "black", "white", "red", "blue", "íŒŒìŠ¤í…”", "pastel"])
            if not has_color and colors:
                # ìƒ‰ìƒì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìƒ‰ìƒ ì¶”ê°€
                color_en = color_map.get(colors[0], colors[0])
                processed_items.append(f"{color_en} {item}")
            else:
                # ì´ë¯¸ ìƒ‰ìƒì´ ìˆìœ¼ë©´ ì˜ì–´ë¡œ ë³€í™˜ë§Œ
                for kr_color, en_color in color_map.items():
                    item = item.replace(kr_color, en_color)
                # ê³µë°± ì •ë¦¬
                item = " ".join(item.split())
                if item:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                    processed_items.append(item)
        
        # ì•„ì´í…œì„ ë ˆì´ì–´ë“œ ë°©ì‹ìœ¼ë¡œ í‘œí˜„ (ì¬í‚·, ê°€ë””ê±´ì´ ìƒì˜ ìœ„ì— ì…í˜€ì§„ í˜•íƒœ)
        # ì¶”ì²œ ìƒí’ˆ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ë” ì •í™•í•œ í‘œí˜„
        if len(processed_items) > 1:
            # ì²« ë²ˆì§¸ ì•„ì´í…œì´ ìƒì˜, ë‚˜ë¨¸ì§€ê°€ ì™¸íˆ¬/ì¬í‚·/ê°€ë””ê±´ì¸ ê²½ìš°
            main_item = processed_items[0]
            outer_items = ", ".join(processed_items[1:])
            items_text = f"{main_item} with {outer_items} over it"
        else:
            items_text = ", ".join(processed_items) if processed_items else "fashion outfit"
        
        # ì¶”ì²œ ìƒí’ˆê³¼ ë§¤ì¹­ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´ í™•ì¸
        # style_infoì—ì„œ ì¶”ì²œ ìƒí’ˆ ì •ë³´ê°€ ìˆë‹¤ë©´ ë” êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„
        if style_info:
            # ì¶”ì²œ ìƒí’ˆ íƒ€ì…ì„ ê³ ë ¤í•˜ì—¬ ì˜ìƒ íƒ€ì… ëª…í™•í™”
            # ì˜ˆ: "í‹°ì…”ì¸ " â†’ "t-shirt", "ì¬í‚·" â†’ "jacket" ë“±
            items_text = items_text.replace("ìƒì˜", "top").replace("í•˜ì˜", "pants").replace("í‹°ì…”ì¸ ", "t-shirt").replace("ì¬í‚·", "jacket")
        
        # ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ (ê°„ê²°í•˜ê²Œ)
        style_keywords = {
            "ìºì£¼ì–¼": "casual style",
            "í¬ë©€": "formal elegant style",
            "íŠ¸ë Œë””": "trendy modern style",
            "ìŠ¤í¬ì¸ ": "sporty athletic style",
            "ë¹ˆí‹°ì§€": "vintage retro style",
            "ëª¨ë˜": "modern contemporary style"
        }
        style_en = style_keywords.get(style, "casual style")
        
        # ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (77 í† í° ì œí•œ ê³ ë ¤)
        # ëª© ì•„ë˜ë§Œ ì¶œë ¥ (ì–¼êµ´ ì œê±°), ì˜ìƒ ëª…í™•í•˜ê²Œ í‘œí˜„
        # ì œí’ˆëª…ì€ í¬í•¨í•˜ì§€ ì•Šê³  ì˜ìƒ ì„¤ëª…ë§Œ ì‚¬ìš©
        
        # ë°”ì§€ ê¸¸ì´ ëª…ì‹œ (ë°˜ë°”ì§€ ë°©ì§€)
        items_text_processed = items_text
        if "ë°”ì§€" in items_text.lower() or "pants" in items_text.lower():
            if "ë°˜ë°”ì§€" not in items_text.lower() and "shorts" not in items_text.lower():
                items_text_processed = items_text.replace("ë°”ì§€", "long pants").replace("pants", "long pants")
        
        # ì•¡ì„¸ì„œë¦¬ ëª…ì‹œ (ëª¨ì, ìº¡ ë“±)
        accessory_keywords = ["ì•¡ì„¸ì„œë¦¬", "accessory", "ìº¡", "cap", "ëª¨ì", "hat"]
        has_accessory = any(kw in items_text.lower() for kw in accessory_keywords)
        if has_accessory:
            items_text_processed += ", wearing cap"
        
        # ëª© ì•„ë˜ë§Œ ì¶œë ¥ (ì–¼êµ´ ì œê±°), ì˜ìƒ ì¤‘ì‹¬
        # ì–¼êµ´ ê´€ë ¨ í‚¤ì›Œë“œ ëª¨ë‘ ì œê±°í•˜ê³  ëª© ì•„ë˜ë¶€í„° ê°•ì¡°
        prompt = f"Fashion photography, {gender_keyword} wearing {items_text_processed}, {style_en}, neck down only, upper body and full body visible, entire outfit visible, legs visible, standing pose, no face visible, head cropped out, focus on clothing, high quality, fashion magazine style, neutral background, studio lighting, 8k"
        
        return prompt
    
    def _generate_with_huggingface_api(self, prompt: str) -> Optional[Image.Image]:
        """Hugging Face Inference API ì‚¬ìš© (ì¶”ì²œ - ë¬´ë£Œ í‹°ì–´)"""
        import time
        
        # ëª¨ë¸ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ, ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” ëª¨ë¸ ìš°ì„ )
        # ìµœê·¼ Hugging Face ì •ì±… ë³€ê²½ìœ¼ë¡œ ì¼ë¶€ ëª¨ë¸ ì ‘ê·¼ ë¶ˆê°€
        # ì‘ë™í•˜ëŠ” ëª¨ë¸ë¡œ ì—…ë°ì´íŠ¸
        models_to_try = [
            "stabilityai/stable-diffusion-2-1",  # ì•ˆì •ì ì¸ ëª¨ë¸
            "runwayml/stable-diffusion-v1-5",   # ì›ë˜ ëª¨ë¸
            "CompVis/stable-diffusion-v1-4"     # ëŒ€ì•ˆ
        ]
        
        # ì¬ì‹œë„ ì„¤ì • (ìµœëŒ€ 3íšŒ, 503 ì—ëŸ¬ ì‹œ ëª¨ë¸ ë¡œë”© ëŒ€ê¸°)
        max_retries = 3
        retry_delay = 5  # ì´ˆ
        current_model_idx = 0
        
        # ì²« ë²ˆì§¸ ëª¨ë¸ë¡œ ì‹œì‘
        model = models_to_try[current_model_idx]
        api_url = f"https://api-inference.huggingface.co/models/{model}"
        
        for attempt in range(max_retries):
            try:
                headers = {
                    "Content-Type": "application/json"
                }
                # API í‚¤ê°€ ì œê³µëœ ê²½ìš°ì—ë§Œ ì‚¬ìš© (ë¬´ë£Œ í‹°ì–´ëŠ” í‚¤ ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥)
                if self.api_key and self.api_key.strip():
                    headers["Authorization"] = f"Bearer {self.api_key.strip()}"
                
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "num_inference_steps": 25,  # ì†ë„ì™€ í’ˆì§ˆ ê· í˜•
                        "guidance_scale": 7.5
                    }
                }
                
                # ìš”ì²­ ì „ì†¡ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                response = requests.post(
                    api_url, 
                    headers=headers, 
                    json=payload,
                    timeout=90  # ëª¨ë¸ ë¡œë”©ì„ ê³ ë ¤í•˜ì—¬ 90ì´ˆë¡œ ì¦ê°€
                )
                
                # ì‘ë‹µ ì²˜ë¦¬
                if response.status_code == 200:
                    image_bytes = response.content
                    if image_bytes:
                        image = Image.open(io.BytesIO(image_bytes))
                        return image
                    else:
                        print("âš ï¸ ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                        return None
                        
                elif response.status_code == 503:
                    # ëª¨ë¸ì´ ë¡œë”© ì¤‘ì¸ ê²½ìš° - ì¬ì‹œë„
                    error_info = {}
                    try:
                        error_info = response.json()
                    except:
                        pass
                    
                    estimated_time = error_info.get("estimated_time", retry_delay)
                    if attempt < max_retries - 1:
                        wait_time = min(int(estimated_time) if isinstance(estimated_time, (int, float)) else retry_delay, 30)
                        print(f"â³ ëª¨ë¸ ë¡œë”© ì¤‘... (ì˜ˆìƒ ëŒ€ê¸°: {wait_time}ì´ˆ, ì‹œë„ {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        print(f"âš ï¸ ëª¨ë¸ ë¡œë”© ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ({estimated_time}ì´ˆ ì˜ˆìƒ)")
                        print("ğŸ’¡ ì ì‹œ í›„ ìˆ˜ë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        return None
                        
                elif response.status_code == 401:
                    # ì¸ì¦ ì˜¤ë¥˜ - ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì‹œë„í•˜ê±°ë‚˜ ì¬ì‹œë„
                    error_info = {}
                    try:
                        error_info = response.json()
                    except:
                        pass
                    
                    # ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì‹œë„
                    if current_model_idx < len(models_to_try) - 1 and attempt < max_retries - 1:
                        current_model_idx += 1
                        model = models_to_try[current_model_idx]
                        api_url = f"https://api-inference.huggingface.co/models/{model}"
                        print(f"âš ï¸ ëª¨ë¸ ì¸ì¦ ì˜¤ë¥˜. ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì‹œë„í•©ë‹ˆë‹¤: {model}")
                        time.sleep(2)
                        continue
                    # ì˜ëª»ëœ í‚¤ê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  ì¬ì‹œë„ (í•œ ë²ˆë§Œ)
                    elif self.api_key and attempt == 0:
                        print("âš ï¸ Hugging Face API í‚¤ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. í‚¤ ì—†ì´ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                        self.api_key = None  # í‚¤ ì œê±°
                        current_model_idx = 0  # ì²« ë²ˆì§¸ ëª¨ë¸ë¡œ ë¦¬ì…‹
                        api_url = f"https://api-inference.huggingface.co/models/{models_to_try[0]}"
                        time.sleep(2)  # ì§§ì€ ëŒ€ê¸° í›„ ì¬ì‹œë„
                        continue
                    else:
                        print("âš ï¸ Hugging Face API ì¸ì¦ ì˜¤ë¥˜ (401)")
                        if not self.api_key:
                            print("ğŸ’¡ ë¬´ë£Œ í‹°ì–´ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")
                            print("ğŸ’¡ ìµœê·¼ ì •ì±… ë³€ê²½ìœ¼ë¡œ ëª¨ë“  ëª¨ë¸ì— API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        else:
                            print("ğŸ’¡ API í‚¤ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                        print("   1. Hugging Face ê³„ì • ìƒì„± (ë¬´ë£Œ)")
                        print("   2. API í† í° ìƒì„± (Read ê¶Œí•œ)")
                        print("      ğŸ”— https://huggingface.co/settings/tokens")
                        print("   3. ì•± ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ ì…ë ¥")
                        return None
                        
                elif response.status_code == 403:
                    # ê¶Œí•œ ë¶€ì¡± ì˜¤ë¥˜
                    error_info = {}
                    try:
                        error_info = response.json()
                    except:
                        pass
                    
                    error_message = error_info.get("error", "ê¶Œí•œ ë¶€ì¡±")
                    print(f"âš ï¸ Hugging Face API ê¶Œí•œ ì˜¤ë¥˜ (403): {error_message}")
                    print("ğŸ’¡ í˜„ì¬ API í† í°ì— Inference API ì‚¬ìš© ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
                    print()
                    print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                    print("   1. Hugging Face ì‚¬ì´íŠ¸ì—ì„œ ê¸°ì¡´ í† í° ì‚­ì œ")
                    print("   2. ìƒˆ í† í° ìƒì„± ì‹œ 'Read' ê¶Œí•œ ì„ íƒ (í•„ìˆ˜)")
                    print("   3. ë˜ëŠ” í”„ë¡œ ìœ ì €ë¡œ ì—…ê·¸ë ˆì´ë“œ (ìœ ë£Œ)")
                    print("      ğŸ”— https://huggingface.co/settings/tokens")
                    print()
                    print("ğŸ’¡ ëŒ€ì•ˆ:")
                    print("   - ë‹¤ë¥¸ ì´ë¯¸ì§€ ìƒì„± ë°©ë²• ì‚¬ìš© (DALL-E, Stable Diffusion ë¡œì»¬ ë“±)")
                    print("   - ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ ë¹„í™œì„±í™” í›„ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œë§Œ ì‚¬ìš©")
                    return None
                        
                elif response.status_code == 429:
                    # ìš”ì²­ í•œë„ ì´ˆê³¼
                    retry_after = response.headers.get("Retry-After", retry_delay)
                    if attempt < max_retries - 1:
                        wait_time = min(int(retry_after) if retry_after.isdigit() else retry_delay, 30)
                        print(f"â³ ìš”ì²­ í•œë„ ì´ˆê³¼. {wait_time}ì´ˆ í›„ ì¬ì‹œë„... (ì‹œë„ {attempt + 1}/{max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        print("âš ï¸ API ìš”ì²­ í•œë„ ì´ˆê³¼")
                        print("ğŸ’¡ ë¬´ë£Œ í‹°ì–´ëŠ” ë¶„ë‹¹ ìš”ì²­ ìˆ˜ ì œí•œì´ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                        return None
                        
                elif response.status_code == 404:
                    # ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì‹œë„
                    error_info = {}
                    try:
                        error_info = response.json()
                    except:
                        pass
                    
                    error_message = error_info.get("error", "ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    print(f"âš ï¸ Hugging Face API ì˜¤ë¥˜ (404): {error_message}")
                    
                    # ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì‹œë„
                    if current_model_idx < len(models_to_try) - 1 and attempt < max_retries - 1:
                        current_model_idx += 1
                        model = models_to_try[current_model_idx]
                        api_url = f"https://api-inference.huggingface.co/models/{model}"
                        print(f"âš ï¸ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì‹œë„í•©ë‹ˆë‹¤: {model}")
                        time.sleep(2)
                        continue
                    else:
                        print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        print("ğŸ’¡ Hugging Faceì˜ ì •ì±…ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ëª¨ë¸ì´ ë¹„ê³µê°œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
                        print("   1. **DALL-E API ì‚¬ìš©** (ê°€ì¥ ì•ˆì •ì , ìœ ë£Œ)")
                        print("   2. **Stable Diffusion ë¡œì»¬ ì‹¤í–‰** (ë¬´ë£Œ, GPU í•„ìš”)")
                        print("   3. **ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ ë¹„í™œì„±í™”** (í…ìŠ¤íŠ¸ ì¶”ì²œë§Œ ì‚¬ìš©)")
                        print("   4. **Hugging Face Pro ê³„ì • ì—…ê·¸ë ˆì´ë“œ** (ìœ ë£Œ)")
                        return None
                        
                else:
                    # ê¸°íƒ€ ì˜¤ë¥˜
                    error_info = {}
                    try:
                        if response.headers.get("content-type", "").startswith("application/json"):
                            error_info = response.json()
                    except:
                        pass
                    
                    error_message = error_info.get("error", response.text[:200] if response.text else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                    print(f"âš ï¸ Hugging Face API ì˜¤ë¥˜ ({response.status_code}): {error_message}")
                    
                    # ì¼ë¶€ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„ ê°€ëŠ¥
                    if response.status_code >= 500 and attempt < max_retries - 1:
                        print(f"â³ ì„œë²„ ì˜¤ë¥˜. {retry_delay}ì´ˆ í›„ ì¬ì‹œë„... (ì‹œë„ {attempt + 1}/{max_retries})")
                        time.sleep(retry_delay)
                        continue
                    
                    return None
                    
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    print(f"â³ ìš”ì²­ ì‹œê°„ ì´ˆê³¼. {retry_delay}ì´ˆ í›„ ì¬ì‹œë„... (ì‹œë„ {attempt + 1}/{max_retries})")
                    time.sleep(retry_delay)
                    continue
                else:
                    print("âš ï¸ ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼)")
                    print("ğŸ’¡ ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return None
                    
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:100]}. {retry_delay}ì´ˆ í›„ ì¬ì‹œë„... (ì‹œë„ {attempt + 1}/{max_retries})")
                    time.sleep(retry_delay)
                    continue
                else:
                    print(f"âš ï¸ Hugging Face API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    import traceback
                    traceback.print_exc()
                    return None
        
        return None
    
    def _generate_with_dalle(self, prompt: str) -> Optional[Image.Image]:
        """OpenAI DALL-E API ì‚¬ìš© (ìœ ë£Œ, ê³ í’ˆì§ˆ)"""
        try:
            from openai import OpenAI
            
            if not self.api_key:
                print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            
            client = OpenAI(api_key=self.api_key)
            
            # DALL-E 3 ì‚¬ìš© (ë” ë‚˜ì€ í’ˆì§ˆ)
            response = client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size="1024x1024",
                quality="standard",
                n=1,
            )
            
            image_url = response.data[0].url
            
            # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            img_response = requests.get(image_url)
            image = Image.open(io.BytesIO(img_response.content))
            
            return image
        except ImportError:
            print("âš ï¸ openai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install openai")
            return None
        except Exception as e:
            print(f"âš ï¸ DALL-E API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_with_prototype(self, outfit_description: Dict, style_info: Dict = None) -> Optional[Image.Image]:
        """í”„ë¡œí† íƒ€ì… ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± (ì˜ìƒë§Œ ë³€ê²½, ë¹ ë¥¸ ì†ë„)"""
        gender = outfit_description.get("gender", "ê³µìš©")
        
        # í”„ë¡œí† íƒ€ì… ë¡œë“œ
        prototype = self.prototype_manager.load_prototype(gender)
        
        # í”„ë¡œí† íƒ€ì…ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not prototype:
            print(f"ğŸ’¡ {gender} í”„ë¡œí† íƒ€ì…ì´ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘... (í•œ ë²ˆë§Œ ìƒì„±ë¨)")
            prototype = self.prototype_manager.generate_prototype(gender, self)
            if not prototype:
                print("âš ï¸ í”„ë¡œí† íƒ€ì… ìƒì„± ì‹¤íŒ¨. ì „ì²´ ì´ë¯¸ì§€ ìƒì„±ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                prompt = self._build_prompt(outfit_description, style_info)
                return self._generate_with_stable_diffusion_local(prompt)
        
        # ì˜ìƒ ë³€ê²½ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(outfit_description, style_info)
        
        # img2img ë°©ì‹ìœ¼ë¡œ ì˜ìƒë§Œ ë³€ê²½
        try:
            from diffusers import StableDiffusionImg2ImgPipeline
            import torch
            import numpy as np
            
            # ì¥ì¹˜ ì„¤ì •
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                device = "mps"
                vae_device = "cpu"
                dtype = torch.float16
            elif torch.cuda.is_available():
                device = "cuda"
                vae_device = "cuda"
                dtype = torch.float16
            else:
                device = "cpu"
                vae_device = "cpu"
                dtype = torch.float32
            
            model_name = "CompVis/stable-diffusion-v1-4"
            
            print("ğŸ¨ í”„ë¡œí† íƒ€ì… ê¸°ë°˜ ì˜ìƒ ë³€ê²½ ì¤‘... (ë¹ ë¥¸ ì†ë„)")
            print(f"â³ ì˜ˆìƒ ì‹œê°„: ì•½ 15-30ì´ˆ (ìµœì í™”ë¨)")
            
            # Img2Img íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                model_name,
                torch_dtype=dtype,
                safety_checker=None,
                requires_safety_checker=False
            )
            
            if device == "mps":
                pipe.vae.to(vae_device)
                pipe.unet.to(device)
                pipe.text_encoder.to(device)
                pipe.enable_attention_slicing()
            else:
                pipe = pipe.to(device)
            
            # í”„ë¡œí† íƒ€ì…ì„ ì´ˆê¸° ì´ë¯¸ì§€ë¡œ ì‚¬ìš©
            # ì–¼êµ´ ì™„ì „ ì œê±°, ëª© ì•„ë˜ë§Œ, í•˜ë°˜ì‹  í¬í•¨
            # ì–¼êµ´ ê´€ë ¨ ëª¨ë“  í‚¤ì›Œë“œ í¬í•¨ (ì™„ì „íˆ ë°©ì§€)
            negative_prompt = "face, head, facial features, eyes, nose, mouth, chin, forehead, cheek, ear, hair, face visible, showing face, portrait, headshot, close-up face, cropped legs, missing legs, cut off at waist, upper body only, shorts, short pants, cropped pants, blurry, watermark, grainy, signature, cut off, draft, low quality, worst quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, mutation, deformed, bad body, blurry, bad anatomy, bad proportions, gross proportions, text, error, missing fingers, missing arms, missing legs, extra digit, fewer digits, cropped, jpeg artifacts, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"
            
            # img2img ìƒì„± (ì˜ìƒë§Œ ë³€ê²½, ì–¼êµ´ì€ ìœ ì§€)
            # strength ì¡°ì •: ë„ˆë¬´ ë†’ìœ¼ë©´ ì–¼êµ´ì´ ë§ê°€ì§ˆ ìˆ˜ ìˆìŒ
            # ì˜ìƒ ë³€ê²½ê³¼ ì–¼êµ´ ë³´ì¡´ì˜ ê· í˜•
            with torch.no_grad():
                result = pipe(
                    prompt=prompt,
                    image=prototype,
                    negative_prompt=negative_prompt,
                    strength=0.7,  # 0.7ë¡œ ì¦ê°€ (ì˜ìƒ ë³€ê²½ í™•ì‹¤íˆ, ì–¼êµ´ì€ ì–´ì°¨í”¼ ì•ˆ ë³´ì„)
                    num_inference_steps=15,  # ì†ë„ ìµœì í™” (15ë‹¨ê³„ë¡œ ê°ì†Œ)
                    guidance_scale=7.0,  # ë¹ ë¥¸ ìƒì„±
                )
            
            image = result.images[0]
            print("âœ… í”„ë¡œí† íƒ€ì… ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            return image
            
        except ImportError:
            print("âš ï¸ diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ì„¤ì¹˜ ë°©ë²•: pip install diffusers accelerate")
            return None
        except Exception as e:
            print(f"âš ï¸ í”„ë¡œí† íƒ€ì… ê¸°ë°˜ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            # fallback: ì „ì²´ ì´ë¯¸ì§€ ìƒì„±
            print("ğŸ’¡ ì „ì²´ ì´ë¯¸ì§€ ìƒì„±ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            prompt = self._build_prompt(outfit_description, style_info)
            return self._generate_with_stable_diffusion_local(prompt)
    
    def _generate_with_stable_diffusion_local(self, prompt: str, negative_prompt: str = None) -> Optional[Image.Image]:
        """ë¡œì»¬ Stable Diffusion ì‚¬ìš© (ë¬´ë£Œ, M2 ë§¥ë¶ ìµœì í™”)"""
        try:
            from diffusers import StableDiffusionPipeline
            import torch
            
            # Apple Silicon (M1/M2) ìµœì í™”
            # MPSëŠ” VAE ë””ì½”ë”©ì—ì„œ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆì–´ CPU ì‚¬ìš© ë˜ëŠ” float32 í•„ìš”
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                # MPSëŠ” VAE ë””ì½”ë”©ì„ ìœ„í•´ CPU ì‚¬ìš© (ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ë¬¸ì œ í•´ê²°)
                device = "mps"  # UNetì€ MPS ì‚¬ìš©
                vae_device = "cpu"  # VAEëŠ” CPU ì‚¬ìš© (ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ë°©ì§€)
                dtype = torch.float16  # MPSëŠ” float16 ì§€ì›
                print("ğŸ Apple Silicon (M1/M2) ê°ì§€ - MPS ë°±ì—”ë“œ ì‚¬ìš© (VAEëŠ” CPU)")
            elif torch.cuda.is_available():
                device = "cuda"
                vae_device = "cuda"
                dtype = torch.float16
            else:
                device = "cpu"
                vae_device = "cpu"
                dtype = torch.float32
                print("âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤ (ëŠë¦¼)")
            
            # M2 ë§¥ë¶ì„ ìœ„í•œ ë” ì‘ê³  íš¨ìœ¨ì ì¸ ëª¨ë¸ ì„ íƒ
            # stable-diffusion-v1-4ê°€ v1-5ë³´ë‹¤ ì•½ê°„ ì‘ê³  ë¹ ë¦„
            model_name = "CompVis/stable-diffusion-v1-4"
            
            # ëª¨ë¸ ë¡œë“œ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œë¨, ì•½ 4GB)
            print(f"Stable Diffusion ëª¨ë¸ ë¡œë“œ ì¤‘... (ì¥ì¹˜: {device}, ëª¨ë¸: {model_name})")
            print("â³ ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤ (ì•½ 4GB, ëª‡ ë¶„ ì†Œìš”)")
            
            try:
                pipe = StableDiffusionPipeline.from_pretrained(
                    model_name,
                    torch_dtype=dtype,
                    safety_checker=None,  # ì†ë„ í–¥ìƒ ë° ë©”ëª¨ë¦¬ ì ˆì•½
                    requires_safety_checker=False
                )
                
                # MPS ë°±ì—”ë“œ ì‚¬ìš© ì‹œ ì¶”ê°€ ìµœì í™”
                if device == "mps":
                    # VAEëŠ” CPUì—ì„œ ì‹¤í–‰ (ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ë¬¸ì œ í•´ê²°)
                    pipe.vae.to(vae_device)
                    # UNetê³¼ text_encoderëŠ” MPS ì‚¬ìš©
                    pipe.unet.to(device)
                    pipe.text_encoder.to(device)
                    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•œ ì„¤ì •
                    pipe.enable_attention_slicing()  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
                else:
                    pipe = pipe.to(device)
                    
            except Exception as load_error:
                print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {load_error}")
                print("ğŸ’¡ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ì¬ì‹œë„ ì¤‘...")
                # ëŒ€ì•ˆ ëª¨ë¸ ì‹œë„
                try:
                    model_name = "runwayml/stable-diffusion-v1-5"
                    pipe = StableDiffusionPipeline.from_pretrained(
                        model_name,
                        torch_dtype=dtype,
                        safety_checker=None,
                        requires_safety_checker=False
                    )
                    pipe = pipe.to(device)
                    if device == "mps":
                        pipe.enable_attention_slicing()
                except Exception as e2:
                    print(f"âš ï¸ ëŒ€ì•ˆ ëª¨ë¸ë„ ë¡œë“œ ì‹¤íŒ¨: {e2}")
                    return None
            
            # ì´ë¯¸ì§€ ìƒì„± (M2 ìµœì í™” ì„¤ì • - ì†ë„ ìµœìš°ì„ )
            print(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘... í”„ë¡¬í”„íŠ¸: {prompt[:80]}...")
            print(f"â³ ìƒì„± ì‹œê°„: ì•½ 20-40ì´ˆ (ìµœì í™”ë¨)")
            
            # CPU fallbackìš© ì¬ë¡œë“œ í•¨ìˆ˜
            def _reload_pipeline_for_cpu():
                """CPU fallbackì„ ìœ„í•´ float32ë¡œ ì¬ë¡œë“œ"""
                print("ğŸ’¡ CPU ëª¨ë“œë¡œ íŒŒì´í”„ë¼ì¸ ì¬ë¡œë“œ ì¤‘...")
                return StableDiffusionPipeline.from_pretrained(
                    model_name,
                    torch_dtype=torch.float32,  # CPUëŠ” float32 í•„ìš”
                    safety_checker=None,
                    requires_safety_checker=False
                ).to("cpu")
            
            # Negative prompt ì¶”ê°€ (ì´ìƒí•œ ì–¼êµ´ ë°©ì§€ - ê°•í™”)
            if negative_prompt is None:
                negative_prompt = "ugly face, distorted face, deformed face, scary face, horror face, ghost face, zombie face, demon face, monster face, alien face, blurry face, bad anatomy, bad proportions, extra limbs, disfigured, gross proportions, malformed limbs, mutated hands, mutated fingers, deformed, bad anatomy, asymmetrical face, crooked nose, weird eyes, unnatural skin, corpse-like, dead eyes, blurry, watermark, grainy, signature, cut off, draft, low quality, worst quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, bad body, blurry, bad anatomy, bad proportions, gross proportions, text, error, missing fingers, missing arms, missing legs, extra digit, fewer digits, cropped, jpeg artifacts, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"
            
            # MPSì—ì„œëŠ” VAE ë””ì½”ë”©ì´ CPUì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ì£¼ì˜
            with torch.no_grad():
                try:
                    result = pipe(
                        prompt,
                        negative_prompt=negative_prompt,  # Negative prompt ì¶”ê°€
                        num_inference_steps=20,  # ì†ë„ ìµœì í™” (ì–¼êµ´ì´ ì•ˆ ë³´ì´ë¯€ë¡œ 20ë‹¨ê³„ë¡œ ì¶©ë¶„)
                        guidance_scale=7.0,  # ë¹ ë¥¸ ìƒì„±
                        height=512,  # M2 ë©”ëª¨ë¦¬ ì œí•œ ê³ ë ¤
                        width=512
                    )
                    
                    # ê²°ê³¼ ì´ë¯¸ì§€ í™•ì¸ ë° ê²€ì¦
                    image = result.images[0]
                    
                    # ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ì²´í¬ (ëª¨ë“  í”½ì…€ì´ ê²€ì€ìƒ‰ì¸ì§€ í™•ì¸)
                    import numpy as np
                    img_array = np.array(image)
                    if np.all(img_array == 0) or np.all(img_array < 10):
                        print("âš ï¸ ê²€ì€ìƒ‰ ì´ë¯¸ì§€ ê°ì§€. CPU ëª¨ë“œë¡œ ì¬ìƒì„± ì¤‘...")
                        # CPUìš© íŒŒì´í”„ë¼ì¸ ì¬ë¡œë“œ (float32)
                        pipe_cpu = _reload_pipeline_for_cpu()
                        pipe_cpu.enable_attention_slicing()
                        negative_prompt = "ugly face, distorted face, deformed face, scary face, horror face, ghost face, zombie face, demon face, monster face, alien face, blurry face, bad anatomy, bad proportions, extra limbs, disfigured, gross proportions, malformed limbs, mutated hands, mutated fingers, deformed, bad anatomy, asymmetrical face, crooked nose, weird eyes, unnatural skin, corpse-like, dead eyes, blurry, watermark, grainy, signature, cut off, draft, low quality, worst quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, bad body, blurry, bad anatomy, bad proportions, gross proportions, text, error, missing fingers, missing arms, missing legs, extra digit, fewer digits, cropped, jpeg artifacts, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"
                        with torch.no_grad():
                            result = pipe_cpu(
                                prompt,
                                negative_prompt=negative_prompt,
                                num_inference_steps=30,  # ì–¼êµ´ í’ˆì§ˆ í–¥ìƒ
                                guidance_scale=8.0,  # ì–¼êµ´ í’ˆì§ˆ í–¥ìƒ
                                height=512,
                                width=512
                            )
                        image = result.images[0]
                    
                except RuntimeError as mps_error:
                    # MPS ê´€ë ¨ ì˜¤ë¥˜ ì‹œ CPUë¡œ fallback
                    if "mps" in str(mps_error).lower() or device == "mps":
                        print("âš ï¸ MPS ì˜¤ë¥˜ ë°œìƒ. CPU ëª¨ë“œë¡œ ì¬ì‹œë„ ì¤‘...")
                        # CPUìš© íŒŒì´í”„ë¼ì¸ ì¬ë¡œë“œ (float32)
                        pipe_cpu = _reload_pipeline_for_cpu()
                        pipe_cpu.enable_attention_slicing()
                        negative_prompt = "ugly face, distorted face, deformed face, scary face, horror face, ghost face, zombie face, demon face, monster face, alien face, blurry face, bad anatomy, bad proportions, extra limbs, disfigured, gross proportions, malformed limbs, mutated hands, mutated fingers, deformed, bad anatomy, asymmetrical face, crooked nose, weird eyes, unnatural skin, corpse-like, dead eyes, blurry, watermark, grainy, signature, cut off, draft, low quality, worst quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, bad body, blurry, bad anatomy, bad proportions, gross proportions, text, error, missing fingers, missing arms, missing legs, extra digit, fewer digits, cropped, jpeg artifacts, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"
                        with torch.no_grad():
                            result = pipe_cpu(
                                prompt,
                                negative_prompt=negative_prompt,
                                num_inference_steps=30,  # ì–¼êµ´ í’ˆì§ˆ í–¥ìƒ
                                guidance_scale=8.0,  # ì–¼êµ´ í’ˆì§ˆ í–¥ìƒ
                                height=512,
                                width=512
                            )
                        image = result.images[0]
                    else:
                        raise
            
            print("âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
            return image
            
        except ImportError:
            print("âš ï¸ diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ì„¤ì¹˜ ë°©ë²•: pip install diffusers accelerate")
            return None
        except Exception as e:
            print(f"âš ï¸ Stable Diffusion ë¡œì»¬ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _generate_with_stability_ai(self, prompt: str) -> Optional[Image.Image]:
        """Stability AI API ì‚¬ìš© (ìœ ë£Œ)"""
        try:
            if not self.api_key:
                print("âš ï¸ STABILITY_AI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            
            api_url = "https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image"
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "text_prompts": [{"text": prompt}],
                "cfg_scale": 7,
                "height": 1024,
                "width": 1024,
                "samples": 1,
            }
            
            response = requests.post(api_url, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                image_base64 = result["artifacts"][0]["base64"]
                import base64
                image_bytes = base64.b64decode(image_base64)
                image = Image.open(io.BytesIO(image_bytes))
                return image
            else:
                print(f"âš ï¸ Stability AI API ì˜¤ë¥˜: {response.status_code}")
                return None
        except Exception as e:
            print(f"âš ï¸ Stability AI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def generate_multiple_outfits(self, outfit_descriptions: List[Dict], 
                                 style_info: Dict = None) -> List[Optional[Image.Image]]:
        """ì—¬ëŸ¬ ì½”ë””ì— ëŒ€í•œ ì´ë¯¸ì§€ ì¼ê´„ ìƒì„±"""
        images = []
        for desc in outfit_descriptions:
            image = self.generate_outfit_image(desc, style_info)
            images.append(image)
        return images


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    generator = OutfitImageGenerator(method="huggingface_api")
    
    outfit_desc = {
        "items": ["red shirt", "blue jeans"],
        "style": "ìºì£¼ì–¼",
        "colors": ["red", "blue"]
    }
    
    image = generator.generate_outfit_image(outfit_desc)
    if image:
        image.save("generated_outfit.png")
        print("âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: generated_outfit.png")

